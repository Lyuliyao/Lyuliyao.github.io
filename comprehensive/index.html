<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
		<title>comprehensve exam</title>
		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/serif.css">
		<style>	
		div.model {
			display: flex;
			justify-content: space-between;
			align-items: center; /* This will vertically center the content */
			margin: 20px 0;
			padding: 10px;
			border: 1px solid #ddd;
			border-radius: 5px;
		}
		div.model .name {
			margin: 0;
			flex: 1;
			color: #444;
			display: flex;
			align-items: center; /* This will vertically center the text */
			justify-content: flex-end; /* This will align the text to the right */
			padding-right: 20px; /* Some spacing between the name and the equation */
		}
		div.model .equation {
			flex: 2;
		}
			figcaption {
			  color: black;
			  font-style: italic;
			  padding: 2px;
			  font-size:large;
			  text-align: center;
			}
			.particle {
				fill: blue;
				stroke: black;
				stroke-width: 1;
			}
			.bond {
				stroke: black;
				stroke-width: 2;
			}
			cite {
				font-size: 0.4em; /* Adjust the font size as needed */
				display: block; /* Optional: To make the citation appear on a new line */
				color:#444
			}
			.theorem, .proposition {
				border: 1px solid #000;
				padding: 10px;
				margin: 10px 0;
			}
			.theorem {
				background-color: #f0f0f0;
			}
			.proposition {
				background-color: #e0e0e0;
			}
			.theorem h4, .proposition h4 {
				margin: 0;
				font-size: 1em;
			}
			.content {
				margin-top: 5px;
				font-size: 0.6em;
			}
		</style>
		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
		<script src="https://d3js.org/d3.v5.min.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script>
		<script type="text/x-mathjax-config">
			MathJax.Hub.Config({
			  TeX: {
				Macros: {
				  bm: ["{\\mathbf{#1}}", 1],
   				  mb: ["{\\mathbf{#1}}", 1],
				diff: "\\mathop{}\\!\\mathrm{d}",
				MLMN: "\\mathcal{L}_\\mathcal{N}",
				bz: "\\mathbf{z}",
				bF: "\\mathbf{F}",
				intd: "\\mathrm{d}",
				mbm:"\\mathbf{m}",
				}
			  }
			});
		  </script>
		<script type="text/javascript">
		window.PlotlyConfig = {MathJaxConfig: 'local'};
		</script>
		<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
		<script src="./figure/md.js">
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<div style="text-align: center;">
						<h4>
							Integration of deep learning technology in the construction of multiscale models
						</h4>
					</div>
					<div style="margin-left: auto; text-align: left; font-size: 0.7em;">
						<p>
							lyuliyao <br>
							Department of Computational Mathematics, Science & Engineering <br>
							Michigan State University
						</p>
					</div>
					<aside class="notes">
						Today, I’m going to talk about how we can integrate deep learning technology to enhance the construction of multiscale models.
					</aside>
                </section>
				<section data-auto-animate data-menu-title="Multi-scale modeling:Background">
					<h4>
						<div style="display:inline">
							Multi-scale modeling:
						</div> 
						<div style="display:inline">
							Background 
						</div>
					</h4>
					<div style="display: flex; align-items: center; justify-content: center; width: 100%;">
						<div>
							<figure style="margin-right: 5%;">
								<img src="./figure/Dirac.png" style="width:70%" alt="Eiffel tower">
							</figure>
							<cite>
								Dirac, Paul Adrien Maurice. "Quantum mechanics of many-electron systems." Proceedings of the Royal Society of London. 1929.
							</cite>
						</div>
						<div>
							<small>
								The right physical principle for most of what we are interested in is already provided by the principles of quantum mechanics (QM), there is no need to look further. <br>
							</small>
						</div>
					</div>
					<aside class="notes">
						Back in 1929, Dirac made a compelling point in his paper. He argued that when it comes to the majority of our interests, we’ve already got what we need with the principles of quantum mechanics (QM). No need to search any further!
					</aside>

				</section>
				
				<section data-auto-animate>
					<h4>
						<div data-id="suptitle" style="display:inline">
							Multi-scale modeling:
						</div> 
						<div style="display:inline">
							Background 
						</div>
					</h4>
					<div style="position:absolute; left: 50%">
						<figure>
							<p><img src="./figure/Andersonphoto-removebg.png"
								style="width:50%"
								alt="Eiffel tower">
							</figure>
							<cite>
								Anderson, Philip W. "More Is Different: Broken symmetry and the nature of the hierarchical structure of science." Science 177.4047 (1972): 393-396.
							</cite>
					</div>
					<div style="position: absolute; right: 50%">
						<div align="left">
							<small>
								The constructionist hypothesis breaks
								down when confronted with <font color="#C82423">the twin
								difficulties of scale and complexity.</font> The
								behavior of large and complex aggregates of elementary particles, it turns
								out, is not to be understood in terms
								of a simple extrapolation of the properties of a few particles. Instead, at
								each level of complexity entirely new
								properties appear, and the understanding of the new behaviors requires research which I think is as fundamental
								in its nature as any other.
							<br>
							</small>
						</div>
					</div>
					<aside class="notes">
						However, the ability to reduce everything to simple fundamental laws does not imply the ability to start from those laws and reconstruct the universe.
						<br>
						This intricate challenge remained largely ignored until Anderson underscored, that the constructivist hypothesis falters when faced with the challenges of scale and complexity
					</aside>
				</section>
				<section data-auto-animate>
					<h4>
						<div style="display:inline">
							Multi-scale modeling:
						</div> 
						<div style="display:inline">
							Background 
						</div>
					</h4>
					<div data-id="Scale">
						<font color="#C82423">Scale</font>
						<br>
					</div>
					<div>
						<small>
							The vastness of scale leads to the well-known <font color="#C82423"> curse of dimensionality </font>. 
						</small>
					</div>
					<div data-id="Complexity">
						<font color="#C82423">Complexity</font>
					</div>
					<aside class="notes">
						The vastness of scale introduces us to the notorious curse of dimensionality. Theoretically, feeding atomic numbers of all involved atoms into QM should give us a complete model. But, with every added atom, the problem’s dimensionality balloons threefold. So, these first-principle models are mainly reserved for simpler cases, proving inefficient for larger system sizes and extended simulation timescales
					</aside>
				</section>					
				<section>
					<h4>
						<div style="display:inline">
							Multi-scale modeling:
						</div> 
						<div style="display:inline">
							Background 
						</div>
					</h4>
					<svg id="mySVG" width="1000" height="600">
						<!-- Draw x and y axes -->
						<line x1="50" y1="550" x2="950" y2="550" style="stroke:black;stroke-width:2" />
						<line x1="50" y1="550" x2="50" y2="50" style="stroke:black;stroke-width:2" />
						<defs>
							<marker id="arrowhead" markerWidth="5" markerHeight="3.5" 
							refX="0" refY="1.75" orient="auto">
								<polygon points="0 0, 5 1.75, 0 3.5" fill="rgb(130, 176, 210)" stroke="rgb(130, 176, 210)" />
							</marker>
						</defs>
						<line id="line_ms" x1="400" y1="450" x2="750" y2="225" stroke="rgb(130, 176, 210)" stroke-width="5" 
						marker-end="url(#arrowhead)" />
						<text id="text_ms" x="525" y="375" font-size="20" fill="rgb(130, 176, 210)" 
						style="text-shadow: 2px 2px 4px rgba(150, 150, 150, 0.5);"
						transform="translate(525,375) rotate(-34) translate(-525,-375)"
						>
							<tspan x="525" dy="1.2em">bottom-up /ab initio </tspan>
							<tspan x="525" dy="1.2em">multi-scale modeling</tspan>
						</text>
						<line id="line_mi_me" x1="50" y1="275" x2="300" y2="275" style="stroke:rgb(87,66,102);stroke-width:3; stroke-dasharray: 5 5;" />
						<line id="line_me_ma" x1="50" y1="125" x2="500" y2="125" style="stroke:rgb(87,66,102);stroke-width:3; stroke-dasharray: 5 5;" />
						<text id="text_mi" x="60" y="375" font-size="25" fill="rgb(87,66,102)" 
						>
							microscopic
						</text>
						<text id="text_me" x="60" y="200" font-size="25" fill="rgb(87,66,102)" 
						>
							mesoscopic
						</text>
						<text id="text_ma" x="60" y="80" font-size="25" fill="rgb(87,66,102)" 
						>
							macroscopic
						</text>
					</svg>
					<script src="./figure/multiscale.js">
					</script>
					<aside class="notes">
						Reduced models are opening up new possibilities, trimming down degrees of freedom by omitting specific details, paving the way for larger scale simulations. For instance, 
						in Molecular Dynamics (MD), the focus is solely on the positions of atoms, leaving out electrons. 
						In Coarse-Grained Molecular Dynamics (CGMD), only collective variables are resolved. 
						And in macroscale models, like Euler equations and Navier–Stokes (NV) equations, 
						the Eulerian viewpoint is focus on density, velocity, and so forth as functions of time and spatial.
						<br>
						However, these reduced models are typically derived empirically – it’s a lot of educated guessing! Making the right guess can often require and represent some serious physical insight. <br>
						<br>
						Take, for example, the force field in MD, the friction term in CGMD, the closed forms in macro models, or the collision term in kinetic theory.
						<br>
						Even in Quantum Mechanics (QM), some level of guessing is needed, whether it’s for the many-body wavefunction in Quantum Monte Carlo (QMC) or the exchange-correlation function in Density Functional Theory (DFT).
						<br>
					</aside>
				</section>
					<section data-auto-animate>
						<h4>
							<div style="display:inline">
								Multi-scale modeling:
							</div> 
							<div style="display:inline">
								Difficulties 
							</div>
						</h4>
						<div data-id="Scale">
							<font color="#C82423">Scale</font>
							<br>
						</div>

						<div data-id="Complexity">
							<font color="#C82423">Complexity</font>
						</div>
						<aside class="notes">
								This guessing game become tricky and often less fruitful due to the inherent complexity.
								As we’ll demonstrate in the first project, traditional intuition-driven models  sometimes oversimplify this inherent complexity significantly
						</aside>
					</section>					
				<section data-auto-animate data-menu-title="Deep Learning and Multiscale Modeling">
					<h4>
						Deep Learning and Multiscale Modeling
					</h4>
					<div>
							<div>
								<h5>
									Protein Structure Prediction
								</h5>
								<cite>
									Jumper, John, et al. "Highly accurate protein structure prediction with AlphaFold." Nature 596.7873 (2021): 583-589.
								</cite>
							</div>

							<div>

							<h5>
								Molecular Dynamics
							</h5>
							<cite>
								Jia, Weile, et al. "Pushing the limit of molecular dynamics with ab initio accuracy to 100 million atoms with machine learning." SC20: International conference for high performance computing, networking, storage and analysis. IEEE, 2020.
							</cite>
							</div>
					</div>
					<aside class="notes">
					The recent advancements in machine learning, with its proficiency in handling multimodal, multi-fidelity data, have opened up new avenues to tackle these challenges. 
					There’s a wealth of research in this area, For example Protein Structure Prediction or Molecular Dynamics.
					However, it’s not all smooth sailing – simply plugging atomic coordinates into a network can lead to a tricky parameter space and complicate training. 
					And, if we lean too heavily on machine learning, we risk overlooking the fundamental laws of physics, potentially ending up with ill-posed problems or unphysical solutions.
					</aside> 
				  </section>
				<section data-auto-animate>
					<h4>
						From Full MD to  Coarse Grained MD
					</h4>
					<svg id="MD1" width="400" height="400"></svg>
					<div>
						<button id="updateValues1">Update</button>
						<script>
							generateAnimation("MD1","updateValues1");
						</script>
					</div>
					<aside class="notes">
						We’re particularly intrigued by the transition from MD to CGMD. Crunching the numbers for a full system can be quite a task! 
						So, why not streamline things and focus on the dynamics of a few CG variables with significantly smaller dimensions?
					</aside>
				</section>
				<section data-auto-animate>
					<div style="display: flex; align-items: center;">
						<!-- SVG and Button Container -->
						<div style="flex: 1; display: flex; flex-direction: column; align-items: center;">
							<svg id="MD2" width="400" height="400" viewBox="0 0 400 400"></svg>
							<button id="updateValues2">Update</button>
							<script>
								d3.select("#MD2");
								generateAnimation("MD2","updateValues2");
							</script>
						</div>
						<!-- Table Container -->
						<div data-id="MZCG">
							\( \mb{Z} = [ \mb{Q}, \mb{P} ] \) 
							<br> 
							\( \mb{Q} = \phi^Q(\mb{q}) \) and \( \mb{P} = \phi^P(\mb{p}) \)
						</div>
					</div>
					<aside class="notes">
							Let’s take a closer look at a system with several molecules. Each molecule has atoms bonded according to a specific structure, represented by solid circles denoted as p and q. Instead of delving into the dynamics of each atom's coordinates and momentum, we’re zoning in on the dynamics of CG variables, represented by Captional p and q. For instance, the Center of Mass (COM) of each molecule is represented as a dotted circle here.
					</aside>
				</section>

				<section data-auto-animate>
					<div data-id="MZCG">
						<div class="equation">
						\[ \dot{\mathbf{P}} = -\nabla V(\mathbf{Q}) - \int_0^t \mathbf{K}(\mathbf{Q}(s), t-s) \mathbf{V}(s) ds   + \mathbf{R}(t) \]
						</div>
					</div>
					<aside class="notes">
						<aside class="notes">
							The governing equation for the Center of Mass (COM) is provided by Mori Zwanzig. The first term is a conserved force, representing the conserved energy in the resolved variable. The second term, a friction force, converts the kinetic energy of the resolved variable into the heat of the unresolved variable. The third term is a random force, converting the heat of the unresolved variable to kinetic energy, akin to Brownian motion. Historically, the complexity of the conserved term has been recognized as not representable by a pairwise formula. However, typically, the state-dependence or the many-body nature of the friction term has been overlooked. Let’s delve into some previous guess regarding the friction term.
							</aside>
							
					</aside>
				</section>
				<section data-auto-animate>
					<!-- Table Container -->
					<div data-id="MZCG">
						<div class="equation">
						\[ \dot{\mathbf{P}} = -\nabla V(\mathbf{Q}) - \int_0^t \mathbf{K}(\mathbf{Q}(s), t-s) \mathbf{V}(s) ds   + \mathbf{R}(t) \]
						</div>
					</div>
					<small>
						<div class="model" data-id="mdpd">
							<div class="name">M-DPD</div>
							<div class="equation">
								\[
								\begin{align}
								\dot{\mb P_i} & = \mb F_i^C - \sum_{j} \mb \Xi(Q_{ij})\mb V_j + \mb R(t).
								\end{align}
								\]
							</div>
						</div>
					</small>
					<aside class="notes">
						DPD Model: This model simplifies by ignoring time dependence and assumes a pairwise formula where the friction is solely along the direction of the pair particle.
					</aside>
				</section>
				<section data-auto-animate>
						<div data-id="MZCG">
							<div class="equation">
							\[ \dot{\mathbf{P}} = -\nabla V(\mathbf{Q}) - \int_0^t \mathbf{K}(\mathbf{Q}(s), t-s) \mathbf{V}(s) ds   + \mathbf{R}(t) \]
							</div>
						</div>
					<small>
						<div class="model" data-id="mdpd">
							<div class="name">M-DPD</div>
							<div class="equation">
								\[
								\begin{align}
								\dot{\mb P_i} & = \mb F_i^C - \sum_{j} \mb \Xi(Q_{ij})\mb V_j + \mb R(t)
								\end{align}
								\]
							</div>
						</div>
						<div class="model" data-id="nmgle">
							<div class="name">NM-GLE</div>
							<div class="equation">
								\[
								\begin{align}
								\dot{\mb P} & = \mb F^C - \int_0^t \mb K(t-s) \mb V(s) \diff s + \mb R(t)
								\end{align}
								\]
							</div>
						</div>
						<aside class="notes">
							GLE Model: This model doesn’t account for spatial dependence, simplifying the representation.
						</aside>
					</small>
				</section>
				<section data-auto-animate>
					<div data-id="MZCG">
						\[ \dot{\mathbf{P}} = -\nabla V(\mathbf{Q}) - \int_0^t \mathbf{K}(\mathbf{Q}(s), t-s) \mathbf{V}(s) ds   + \mathbf{R}(t) \]
					</div>
					<small>
					<div class="model" data-id="mdpd">
						<div class="name">M-DPD</div>
						<div class="equation">
							\[
							\begin{align}
							\dot{\mb P_i} & = \mb F_i^C - \sum_{j} \mb \Xi(Q_{ij})\mb V_j + \mb R(t).
							\end{align}
							\]
						</div>
					</div>
					<div class="model" data-id="nmgle">
						<div class="name">NM-GLE</div>
						<div class="equation">
							\[
							\begin{align}
							\dot{\mb P} & = \mb F^C - \int_0^t \mb K(t-s) \mb V(s) \diff s + \mb R(t).
							\end{align}
							\]
						</div>
					</div>
					<div class="model" data-id="nmdpd">
						<div class="name">NM-DPD</div>
						<div class="equation">
							\[
							\begin{align}
							\dot{\mb P}_i &=  \mb F^C_{i} - \sum_j \int_0^t \mb \Xi(Q_{ij},t-s) \mb V_{ij}(s) \diff s +  \sum_j\mb R_{ij}(t),
							\end{align}
							\]
						</div>
						<aside class="notes">
							NM-DPD Model: This model takes into account state and time dependence but is still pairwise. In this project, we aim to highlight that these formulas oversimplify the intrinsic complexity of the dynamics and fail to preserve many interesting properties of the CG system. Before we explore using machine learning to learn a friction tensor, we want to emphasize some physical properties that the friction tensor should satisfy.
							</aside>
					</div>
				</small>
				</section>
				<section data-auto-animate>
					<div data-id="SPD">
						Semi-Positive Definite 
					</div>
					<!-- <div>
						<p>
							\[ \mathbf{K}(\mathbf{Q}, t) \approx \bm\Xi(\mb Q){\rm e}^{- \bm\Lambda t}\bm\Xi(\mb Q)^T\]
						</p>
					</div>
					<aside class="notes">
						Semi-Positive defined. 
					</aside> -->
				</section>
				<section data-auto-animate>
					<div data-id="SPD">
						Semi-Positive Definite 
					</div>
					<div data-id="TI">
						Translation Invariance
					</div>
					<div>
						<p>
						$$
							\begin{align}
							\mathbf{K}(\mathbf{Q}_1 +\mathbf{b}, \cdots,\mathbf{Q}_M +\mathbf{b},t) &= \mathbf{K}(\mathbf{Q}_1, \cdots,\mathbf{Q}_M,t) \\
							\end{align}
						$$
						</p>
					</div>
					<aside class="notes">
						The friction tensor need to be positive defined.
					</aside>
				</section>

				<section data-auto-animate>
					<div data-id="SPD">
						Semi-Positive Definite 
					</div>
					<div data-id="TI">
						Translation Invariance
					</div>
					<div data-id="RS">
						Rotation Symmetries
					</div>
					<div>
						<p>
							$$
								\begin{align}
								\mathbf{K}(\mathbf{Q}_1 \mathcal{U} , \cdots,\mathbf{Q}_M \mathcal{U}  ,t) &= \mathcal{U} \mathbf{K}(\mathbf{Q}_1, \cdots,\mathbf{Q}_M,t) \mathcal{U}^T \\
								\end{align}
							$$
						</p>
					</div>
				</section>

				<section data-auto-animate>
					<div data-id="SPD">
						Semi-Positive Definite 
					</div>
					<div data-id="TI">
						Translation Invariance
					</div>
					<div data-id="RS">
						Rotation Symmetries
					</div>
					<div data-id="PS">
						Permutation Symmetries
					</div>
					<div>
						<p>
							$$
								\begin{align}
								\mathbf{K}_{ij}(\mathbf{Q}_{\sigma(1)} , \cdots,\mathbf{Q}_{\sigma(M)}  ,t) &=  \mathbf{K}_{{\sigma(i)}{\sigma(j)}}(\mathbf{Q}_{\sigma(1)}, \cdots,\mathbf{Q}_{\sigma(M)},t)  \\
								\end{align}
							$$
						</p>
					</div>
				</section>
				<section data-auto-animate>
					<div style="display: flex; justify-content: space-around;"></divstyle>
						<div>
							<svg id="canvas1"></svg>
							<p>\(\mathbf{K}\)(<span id="input11"></span> , <span id="input12"></span> , <span id="input13"></span>,t)</p>
							<div class="matrix">
							<table style="font-size: 30px;"">
								<tr>
									<td>k<span id="gamma111"><sub>1</sub></span><span id="gamma112"><sub>1</sub></span></td>
									<td>k<span id="gamma113"><sub>1</sub></span><span id="gamma121"><sub>2</sub></span></td>
									<td>k<span id="gamma114"><sub>1</sub></span><span id="gamma131"><sub>3</sub></span></td>
								</tr>
								<tr>
									<td>k<span id="gamma122"><sub>2</sub></span><span id="gamma115"><sub>1</sub></span></td>
									<td>k<span id="gamma123"><sub>2</sub></span><span id="gamma125"><sub>2</sub></span></td>
									<td>k<span id="gamma124"><sub>2</sub></span><span id="gamma132"><sub>3</sub></span></td>
								</tr>
								<tr>
									<td>k<span id="gamma133"><sub>3</sub></span><span id="gamma116"><sub>1</sub></span></td>
									<td>k<span id="gamma134"><sub>3</sub></span><span id="gamma126"><sub>2</sub></span></td>
									<td>k<span id="gamma135"><sub>3</sub></span><span id="gamma136"><sub>3</sub></span></td>
								</tr>
								<tr>
								</tr>
							</table>
						</div>
							<button id="clearButton1">Clear</button>
						</div>
						<div>
						<svg id="canvas2"></svg>
						<p>\(\mathbf{K}\)(<span id="input21"></span> , <span id="input22"></span> , <span id="input23"></span>,t)</p>
						<div class="matrix">
							<table style="font-size: 30px;">
								<tr>
									<td>k<span id="gamma211"><sub>1</sub></span><span id="gamma212"><sub>1</sub></span></td>
									<td>k<span id="gamma213"><sub>1</sub></span><span id="gamma221"><sub>2</sub></span></td>
									<td>k<span id="gamma214"><sub>1</sub></span><span id="gamma231"><sub>3</sub></span></td>
								</tr>
								<tr>
									<td>k<span id="gamma222"><sub>2</sub></span><span id="gamma215"><sub>1</sub></span></td>
									<td>k<span id="gamma223"><sub>2</sub></span><span id="gamma225"><sub>2</sub></span></td>
									<td>k<span id="gamma224"><sub>2</sub></span><span id="gamma232"><sub>3</sub></span></td>
								</tr>
								<tr>
									<td>k<span id="gamma233"><sub>3</sub></span><span id="gamma216"><sub>1</sub></span></td>
									<td>k<span id="gamma234"><sub>3</sub></span><span id="gamma226"><sub>2</sub></span></td>
									<td>k<span id="gamma235"><sub>3</sub></span><span id="gamma236"><sub>3</sub></span></td>
								</tr>
								<tr>
								</tr>
							</table>
						</div>
						<button id="clearButton2">Clear</button>
						</div>
						<script>
							const svg1 = d3.select("#canvas1")
								.attr("width", 300)
								.attr("height", 300);
							const svg2 = d3.select("#canvas2")
								.attr("width", 300)
								.attr("height", 300);
							const atoms1 = [
								{cx: 175, cy: 75, color: "rgba(0,47,167)", name: "r1"},
								{cx: 250, cy: 150, color: "rgba(187,151,39)", name: "y1"},
								{cx: 175, cy: 225, color: "rgba(84,179,69)", name: "g1"},
							];
							const atoms2 = [
								{cx: 175, cy: 75, color: "rgba(0,47,167)", name: "r1"},
								{cx: 250, cy: 150, color: "rgba(187,151,39)", name: "y1"},
								{cx: 175, cy: 225, color: "rgba(84,179,69)", name: "g1"},
							];
							let clickedAtoms1 = [];
							let clickedAtoms2 = [];

					
							const circles1 = svg1.selectAll("circle")
								.data(atoms1)
								.enter()
								.append("circle")
								.attr("cx", d => d.cx)
								.attr("cy", d => d.cy)
								.attr("r", 40)
								.style("fill", d => d.color)
								.on("mouseover", function (d, i) {
									d3.select(this)
									  .transition()
									  .duration(300)
									  .attr("r", 60);
								})
								.on("mouseout", function (d, i) {
									d3.select(this)
									  .transition()
									  .duration(300)
									  .attr("r", 40);
								})
								.on("click", function (d, i) {
								if (clickedAtoms1.length < 3) {
									clickedAtoms1.push(i);
									svg1.append("text")
										.attr("x", i.cx)
										.attr("y", i.cy)
										.attr("text-anchor", "middle")
										.attr("dominant-baseline", "central")
										.style("fill", "white")
										.style("font-size", "20px")
										.text(clickedAtoms1.length);
									updateEquation1();
								}
							});
					
						const circles2 = svg2.selectAll("circle")
								.data(atoms2)
								.enter()
								.append("circle")
								.attr("cx", d => d.cx)
								.attr("cy", d => d.cy)
								.attr("r", 40)
								.style("fill", d => d.color)
								.on("mouseover", function (d, i) {
									d3.select(this)
									  .transition()
									  .duration(300)
									  .attr("r", 60);
								})
								.on("mouseout", function (d, i) {
									d3.select(this)
									  .transition()
									  .duration(300)
									  .attr("r", 40);
								})
								.on("click", function (d, i) {
									if (clickedAtoms2.length < 3) {
										clickedAtoms2.push(i);
										svg2.append("text")
											.attr("x", i.cx)
											.attr("y", i.cy)
											.attr("text-anchor", "middle")
											.attr("dominant-baseline", "central")
											.style("fill", "white")
											.style("font-size", "20px")
											.text(clickedAtoms2.length);
										updateEquation2();
									}
								});
								function updateEquation1() {
								for (let i = 0; i < 3; i++) {
									if (i < clickedAtoms1.length) {
										let color = clickedAtoms1[i].color;
										d3.select("#input1" + (i + 1))
											.style("color", color)
											.text("Q" + (i + 1));
										for (let j = 1; j <= 7; j++) {
											d3.select("#gamma1" + (i + 1) + j)
												.style("color", color);
										}
									} else {
										d3.select("#input1" + (i + 1))
											.style("color", "black")
											.text(" ");
									}
								}
							}
					
							function updateEquation2() {
								for (let i = 0; i < 3; i++) {
									if (i < clickedAtoms2.length) {
										console.log("color: ", clickedAtoms2[i]);
										d3.select("#input2" + (i + 1))
											.style("color", clickedAtoms2[i].color)
											.text("Q"+ ( i + 1));
										for (let j=1; j<=7;j++){
										d3.select("#gamma2"+ ( i + 1) +j)
											.style("color",clickedAtoms2[i].color);
										}
									} else {
										d3.select("#input2" + (i + 1))
											.style("color", "black")
											.text(" ");
									}
								}
							}
							d3.select("#clearButton1")
							.on("click", function () {
								clickedAtoms1 = [];
								svg1.selectAll("text").remove();
								updateEquation1();
							});
						d3.select("#clearButton2")
							.on("click", function () {
								clickedAtoms2 = [];
								svg2.selectAll("text").remove();
								updateEquation2();
							});
						</script>
					</div>
					<aside class="notes">
						<p>When it comes to permutation symmetry, imagine having two identical systems, but different observers assign different indices to them. The friction tensor between these systems should still be related, right? It makes sense because the indices we assign don’t actually change the system itself. This concept is similar to the translation and rotation symmetries we’ve talked about before – the axis we choose doesn’t change the fundamental physics of the situation.</p>
					</aside>
					
				</section>
				<section data-auto-animate>
					<div data-id="SPD">
						Semi-Positive Definite 
					</div>
					<div>
						<p>
							\[ \mathbf{K}(\mathbf{Q}, t) \approx \bm\Xi(\mb Q){\rm e}^{- \bm\Lambda t}\bm\Xi(\mb Q)^T\]
						</p>
					</div>
					<aside class="notes">
						When it comes to being Semi-Positive Defined, we can tackle this by assuming that time and spatial contribution are sepaerable. All spatial symmetry is inherited by the capital Xi. So, our focus is on constructing a symmetric Xi first.
						</aside>
						
				</section>
				<section data-auto-animate>
					<div style="display: flex; align-items: center;">
						<!-- SVG and Button Container -->
						<div style="flex: 1; display: flex; flex-direction: column; align-items: center;">
							<figure>
								<p><img src="./figure/Q.png">
								</figure>
						</div>
						<div>
							<h4>
								Environemnt Embeded Coordinate
							</h4>
							\( \hat{ \mathbf Q}^k_i = \mathbf{Q}_i \oplus \sum_{l\in\mathcal{N}_i} f^k(|\mathbf{Q}_{il}|) \mathbf{Q}_{il} \) <br> 
							\( f:\mathbb R \to \mathbb{R}^K\)
						</div>
						<aside class="notes">
							For each molecule, we construct an environment-embedded coordinate. Here, Q_ij represents the distance vector between each pair of molecules. By utilizing the coordinates of particles within the cutoff distance of the central coordinate, we determine K general coordinates. Specifically, f acts as a network, and Qij is the distance vector of the central vector. By applying some nonlinear activation to the original coordinate, we obtain a general coordinate that is symmetric in R3K.
							</aside>
							
				</section>
				<section data-auto-animate >
					<div style="display: flex; align-items: center;">
						<div style="flex: 1; display: flex; flex-direction: column; align-items: center;">
							<figure>
								<p><img src="./figure/Q.png">
							</figure>
							<figure>
								<p><img src="./figure/hatQ.png">
							</figure>
						</div>
						<div>
							<h4>
								Environemnt Embeded Coordinate
							</h4>
						<p>
							\( \hat{ \mathbf Q}^k_i = \mathbf{Q}_i \oplus \sum_{l\in\mathcal{N}_i} f^k(|\mathbf{Q}_{il}|) \mathbf{Q}_{il} \) <br> 
							\( f:\mathbb R \to \mathbb{R}^K\) <br> 
							\( \hat{\mathbf{Q}}_{ij}^{k} = \hat{\mathbf{Q}}_i^{k} - \hat{\mathbf{Q}}_j^{k} \)  <br>
						</p>
						</div>
						</div>	
						<aside class="notes">
							Notice that the general coordinate is not in the original position, but it has many-body features embedded. From this, we can construct many-body determined features for each pair.
							</aside>
				</section>
				<section data-auto-animate >
					<div style="display: flex; align-items: center;">
						<div style="flex: 1; display: flex; flex-direction: column; align-items: center;">
							<figure>
								<p><img src="./figure/hatQ.png">
							</figure>
						</div>
						<div>
							<p>
								\[
								\begin{split}
								& \boldsymbol{\Xi}^n_{ij} &= \sum_{k=1}^K h_{n,k}(\hat{ \mathbf Q}_{ij}^T \hat{ \mathbf Q}_{ij} ) \hat{ \mathbf Q}_{ij}^k \otimes \hat{ \mathbf Q}_{ij}^k\\ 
								& &+ h_{n,0}(\hat{ \mathbf Q}_{ij}^T \hat{ \mathbf Q}_{ij} ) \mathbf{I} \\
								&\boldsymbol{\Xi}^n_{ii} &= -\sum_{j\in \mathcal{N}_i} \boldsymbol{\Xi}^n_{ij} \\
								&h&: \mathbb{R}^{K\times K}\to \mathbb{R}^{N(K+1)}
								\end{split}
								\]
							</p>
						</div>
						<aside class="notes">
							Using these features, we can construct the capital Xi for each pair. And, based on Newton's third law, we can also compute the diagonal term.
							</aside>
					</div>	
				</section>
				<section data-auto-animate >
					<div>
						<p>
							\[
							\begin{split}
							\mathbf{K}(\mathbf{Q}, t)  &= \bm\Xi(\mb Q){\rm e}^{ - \bm\Lambda t}\bm\Xi(\mb Q)^T \\
							\bm\Xi(\mb Q) & \in \mathbb{R}^{3M\times 3MN}\\
							\bm\Lambda& \in \mathbb{R}^{3MN\times 3MN}\\
							\end{split}
							\]
						</p>
					</div>
					<aside class="notes">
						Now, with a symmetric capital Xi, we can construct the memory with time dependence.
						</aside>
				</section>
				<section data-auto-animate >
					<div style="display: flex; align-items: center;">
						<div style="flex: 1; display: flex; flex-direction: column; align-items: center;">
							<div>
								<p>
									\[
									\begin{split}
									\mathbf{K}(\mathbf{Q}, t)  &= \bm\Xi(\mb Q){\rm e}^{ - \bm\Lambda t}\bm\Xi(\mb Q)^T \\
									\bm\Xi(\mb Q) & \in \mathbb{R}^{3M\times 3MN}\\
									\bm\Lambda& \in \mathbb{R}^{3MN\times 3MN}\\
									\end{split}
									\]
								</p>
							</div>
						</div>
						<div>
							<p>
								\[
								\begin{split}
								\bm\Lambda &= \hat{\bm \Lambda}\otimes \mb I \\
								\hat{\bm\Lambda} &\in \mathbb{R}^{N\times N} \\
								\mb I &\in \mathbb{R}^{3M\times 3M} \\
								\hat{\bm \Lambda} &= \hat{\mb L}\hat{\mb L}^T + \hat{\mb L}^a \\
								\end{split}
								\]
							</p>
						</div>
						<aside class="notes">
							The time dependence is independent of position, and by permutation symmetry, we can assume it is purely isotropic. We learn the symmetric and anti-symmetric parts separately, ensuring the symmetric part is semi-positive preserved.
							</aside>
					</div>
				</section>
				  <section data-auto-animate data-menu-title="RDF">
					<div style="display: flex; justify-content: center; align-items: center;">
						<div>
							<h5>
								Radial Distribution Functio (RDF)
							</h5>
							<p>
								<small>
									\[ g(r) = \frac{V}{N} \cdot \frac{{dN(r)}}{{4\pi r^2 dr}} \]
								</small>
							</p>
						</div>
						<div
							id=rdf
							class="plotly-graph-div"
							style="height:400; width:400;">
						</div>
						<script type="text/javascript" src="./text/rdf.js">
						</script>
					</div>
					<aside class="notes">
						First up, we’re diving into some structural properties, like the Radial Distribution Function (RDF). It’s interesting to note that the RDF relies solely on the conservative term, and our application of the many-body conservative term allows us to nail it precisely!
						</aside>
				  </section>
				  <section data-auto-animate data-menu-title="VACF">
					<div style="display: flex; justify-content: center; align-items: center;">
						<div>
							<h5>
								Velocity auto correlation function (VACF)
							</h5>
							<p>
								<small>
									\[ \frac{\lt v_i(t) \cdot v_i(0) \gt }{ \lt v_i(0) \cdot v_i(0) \gt } \]
								</small>
							</p>
						</div>

						<div
							id=vacf
							class="plotly-graph-div"
							style="height:400; width:400;">
						</div>
						<script type="text/javascript" src="./text/vacf.js">
						</script>
					</div>
					<aside class="notes">
						Next, we’re exploring isotropic dynamic properties, such as the Velocity Auto Correlation Function (VACF), which measures the time correlation of a particle's velocity. Notice how our model, marked as NM-MB (red), and the state-independent GLE (purple) are spot on! This is because the GLE model uses the memory kernel as a free parameter to fit the VACF. As Von Neumann said, with four free parameters, one can draw an elephant! It’s not surprising, but it doesn’t mean GLE can recover the dynamics accurately.
						</aside>
					</section>
					<section data-auto-animate data-menu-title="VCCF">
						<div style="display: flex; justify-content: center; align-items: center;">
							<div>
								<h5>
									Velocity cross correlation function (VCCF)
								</h5>
								<p>
								<small>
									\[ C^{xx}(t; r_0) = \mathbb{E}[\mathbf{V}_i(0)\cdot\mathbf{V}_j(t) \vert Q_{ij}(0) = r_0] \]
								</small>
								</p>
							</div>
							<div
								id=vccf
								class="plotly-graph-div"
								style="height:400; width:400;">
							</div>
							<script type="text/javascript" src="./text/vccf.js">
							</script>
						</div>
						<aside class="notes">
							If we delve deeper into metrics like the Velocity Cross Correlation Function (VCCF), which represents the momentum transfer rate at a fixed distance, we see that GLE falls short, but our model still captures the main contribution. It’s also worth noting that NM-DPD shows decent results, but that’s because it uses VCCF as a fitting target.
							</aside>
					</section>
					<section data-auto-animate data-menu-title="VHF">
						<div style="display: flex; justify-content: center; align-items: center;">
							<div>
								<h5>
									van Hove function (VHF)
								</h5>
								<p>
									<small>
									\( G(r, t) \propto \frac{1}{M^2} \sum_{j\neq i}^M \delta(\Vert \mathbf{Q}_i(t) - \mathbf{Q}_j(0)\Vert - r) \).
								</small>
									</p>
							</div>
							<div
								id=vhf
								class="plotly-graph-div"
								style="height:400; width:400;">
							</div>
							<script type="text/javascript" src="./text/vhf.js">
							</script>
						</div>
						<aside class="notes">
							Let’s look at another property, the van Hove Function (VHF), which is essentially a time evolution of the RDF. It measures the probability of finding a particle at time t with distance r from the central particle. Here, both NM-DPD and NM-GLE fall short, but our model stands strong!
							</aside>
					</section>
					<section data-auto-animate data-menu-title="Hydromode">
						<div style="display: flex; justify-content: center; align-items: center;">
							<div>
								<h5>
									normalized correlations of the Longitudinal Hydrodynamic Modes
									<!-- normalized correlations of the longitudinal and transverse hydrodynamic modes -->
								</h5>
								<p>
								<small>
									\[ 
									\begin{split}
									C_L(t) &= \langle \tilde{u}_1(t)\tilde{u}_1(0)\rangle \\
									\tilde{\mb u} &= 1/M\sum_{j=1}^M \mb V_j {\rm e}^{i\mb k \cdot \mb Q_j}
									\end{split}
									\]
								</small>
								</p>
							</div>
							<div
								id=long_corr
								class="plotly-graph-div"
								style="height:400; width:400;">
							</div>
							<script type="text/javascript" src="./text/long_corr.js">
							</script>
							<aside class="notes">
								We can also explore the correlation of wave propagation modes, which represent the coefficients of the linearized NV equation in the spectrum domain. In the longitudinal direction, both NM-DPD and our model perform well, as the conservative term mainly contributes in this direction.
								</aside>
					</section>
					<section data-auto-animate data-menu-title="Hydromode">
						<div style="display: flex; justify-content: center; align-items: center;">
							<div>
								<h5>
									normalized correlations of the Transverse Hydrodynamic Modes
									<!-- normalized correlations of the longitudinal and transverse hydrodynamic modes -->
								</h5>
								<p>
								<small>
									\[ 
									\begin{split}
									C_L(t) &= \langle \tilde{u}_2(t)\tilde{u}_2(0)\rangle \\
									\tilde{\mb u} &= 1/M\sum_{j=1}^M \mb V_j {\rm e}^{i\mb k \cdot \mb Q_j}
									\end{split}
									\]
								</small>
								</p>
							</div>
							<div
								id=trans_corr
								class="plotly-graph-div"
								style="height:400; width:400;">
							</div>
							<script type="text/javascript" src="./text/trans_corr.js">
							</script>
							<aside class="notes">
								However, when it comes to the transverse term, our model clearly outshines the others.
								</aside>
					</section>
						<section data-auto-animate>
							<h4>Coarse-Graining Variable Optimization</h4>
							<aside class="notes">
								<p>Let’s delve into the intricacies, not just limited to dynamic equations, but extending to the selection of dynamic coordinates. Consider water models as a prime example. We have various coordinates, ranging from one to six, each designed to represent water and capture distinct behaviors. The careful selection of these coordinates is deeply rooted in physical insight, akin to the model-building we’ve discussed earlier.</p>
								<p>As we navigate through the complexity of molecular structures, this task becomes increasingly challenging. Here, the prospect of data-driven coordinate selection emerges as a potential alternative to the traditional approach, which is predominantly reliant on human intelligence.</p>
								<p>In the realm of extensive CGMD systems, the center of mass (COM) takes center stage. However, when it comes to modeling non-Newtonian fluids, known for their complex flow behavior, accurately capturing the deformation of polymers is essential. This crucial aspect is often oversimplified when the focus is solely on COM. Therefore, our ongoing project aims to underscore the significance of dynamic coordinate selection in faithfully depicting macroscopic rheology behavior.</p>
							</aside>
						</section>
					</section>
					<section data-auto-animate>
						<h4>Coarse-Graining Variable Optimization</h4>
						<div data-id="allmap">
						\[
						\begin{split}
						\phi(\mathbf{z}) &= \left[\phi^Q (\mathbf{q}), \phi^P (\mathbf{p})\right] \\
						\phi &: \mathbb{R}^{6nM} \to \mathbb{R}^{6NM}
						\end{split}
						\]
						</div>
						<aside class="notes">
							<p>For simplicity, let’s switch up our notation a bit. Imagine we have a full MD system made up of \( M \) molecules, each containing \( n \) atoms. To make things straightforward, we'll assume the mass of each is \( 1 \).</p>
							<p>We represent the CG variables by associating each molecule with \( N \) CG particles.</p>
						</aside>
					</section>
					<section data-auto-animate>
						<h4>Coarse-Graining Variable Optimization</h4>
						<div data-id="allmap" >
							\[
							\begin{split}
							\phi(\mathbf{z}) &= \left[\phi^Q (\mathbf{q}), \phi^P (\mathbf{p})\right] \\
							\phi &: \mathbb{R}^{6nM} \to \mathbb{R}^{6NM}
							\end{split}
							\]
							</div>
						<div>
						\[
						\begin{split}
						\phi &=\otimes^M\hat{\phi} \\
						\hat{\phi} &: \mathbb{R}^{6n} \to \mathbb{R}^{6N}
						\end{split}
						\]
						</div>
						<aside class="notes">
							<p>Let’s say the CG variable is figured out based on what’s going on inside the molecule. So, we can use a direct product formula to represent it, making our lives a bit easier!</p>
						 </aside>
						 
						
					</section>
					<section data-auto-animate>
						<p>In this project, we assume that the coarse-grained map is defined by a matrix \( W \in \mathbb{R}^{N\times n} \). We desire that \( W \) satisfies several properties:</p>
						<ul>
							<li>Each element \( w_{ij} \) of the matrix \( W \) is in the interval \([0,1]\).</li>
							<li>The sum of the elements in each column of \( W \) is 1, i.e., \( \sum_i w_{ij} =1 \).</li>
						</ul>
						<aside class="notes">
							<p>We’re also assuming the CG variables are linear and can be figured out by a matrix W, which has a few properties we need to keep in mind…</p>
							<p> 
								The second property make sure we can still used the Netwon's thrid law rather than deal with diagnoal term separately
							</p>
						</aside>
					</section>

					<section data-auto-animate>
						The CG map is thus defined as:
					\[
					\begin{split}
					\hat{\phi}^Q_W(\mathbf{z}^I) &= \frac{\sum_{j} w_{ij} \mathbf{q}^I_j}{\sum_j w_{ij}}\\
					\hat{\phi}^P_W(\mathbf{z}^I) &= \sum_{j} w_{ij} \mathbf{p}^I_j;
					\end{split}
					\]
					<aside class="notes">
						<p>So, this is how we define the CG map based on W</p>
					 </aside>
					 
					</section>
					<section data-auto-animate>
						<h4>
							Maximum Rayleigh quotient to obtain CG variable
						</h4>
					</section>
					<aside class="notes">
						<p>Next, we address the determination of the matrix W through an optimization problem.</p>
					 </aside>
					<section data-auto-animate>
						<h4>
							Maximum Rayleigh quotient to obtain CG variable
						</h4>
						<div data-id="liu">
							\[
							\mathbf{\phi}_W(\mathbf{z}(t)) = {\rm e}^{\mathcal{L} t}\phi_W(\mathbf{z}(0))
							\]
						</div>
						<aside class="notes">
							<p>The temporal evolution of the CG variable is characterized by a Liouville operator.</p>
						 </aside>
					</section>
					<section data-auto-animate>
						<h4>
							Maximum Rayleigh quotient to obtain CG variable
						</h4>
						<div data-id="liu">
							\[
							\mathbf{\phi}_W(\mathbf{z}(t)) = {\rm e}^{\mathcal{L} t}\phi_W(\mathbf{z}(0))
							\]
						</div>
						<div>
							\[
							\max_W \frac{\phi_W(\mb z(0)){\rm e}^{\mathcal{L} t}\phi_W(\mathbf{z}(0))}{\phi_W(\mathbf{z}(0)) \phi_W(\mathbf{z}(0))}
							\]
						</div>
						<aside class="notes">
							<p>The slowest mode of the Liouville operator can be discerned utilizing the Maximum Rayleigh quotient. This is intrinsically related to the auto-correlation function previously discussed. In practice, we employ VACF exclusively and opt for a time domain rather than a specific time.</p>
						 </aside>
					</section>
					<section data-auto-animate>
						<h4>
							1D Reverse Poiseuille Flow
						</h4>
						<div style="display: flex; justify-content: center; align-items: center;">
						<div>
							<figure>
								<p><img src="./figure/res_flow.png" style="width: 50%; height: 50%;"></p>
							</figure>
						</div>
						</div>
						<aside class="notes">
							<p>We apply our methodology to a reverse Poiseuille flow. By dividing the domain in the z direction, a reverse force is applied in the opposite direction along the x-axis, resulting in a distinct velocity profile in the x component of the average velocity in the z direction.</p>
						 </aside>
					</section>
					<section data-auto-animate data-menu-title="VHF">
						<h4>
							1D Reverse Poiseuille Flow
						</h4>
						<div style="display: flex; justify-content: center; align-items: center;">
						<div>
							<figure>
								<p><img src="./figure/res_flow.png" ></p>
							</figure>
						</div>
						<div style="display: flex; justify-content: center; align-items: center;">
							<div
								id=vx
								class="plotly-graph-div"
								style="height:300; width:300;">
							</div>
							<script type="text/javascript" src="./text/vx.js">
							</script>
						</div>
						
						</div>
						<aside class="notes">
							<p>During this process, the deformation of the polymer is intertwined with fluid flow, exhibiting rheological behavior. It is demonstrable that with additive CG, we are able to capture these contributions, which are oversimplified by COM.</p>
						 </aside>
					</section>
					<section data-auto-animate>
						<h4>
							Consensus based Enhance Sampling
						</h4>
						<aside class="notes">
							<p>Beyond the challenges of exploring dynamic equations and variables, a significant difficulty lies in sampling. The ability to obtain a representative dataset is pivotal for achieving reliable data-driven results.</p>
						 </aside>
					</section>
					<section data-auto-animate>
						<h4>
							(Free) Energy Surface
						</h4>
						<div>
							<figure>
								<p>
									<img  style="width:50%" src="./figure/FES.jpeg">
								</p>
							</figure>
							<cite>
								Dill, Ken A., and Justin L. MacCallum. "The protein-folding problem, 50 years on." science 338.6110 (2012): 1042-1046.
							</cite>
							<aside class="notes">
								<p>A significant challenge is the construction of the Free Energy Surface (FES). Constructing an FES typically necessitates exploring ground states, meta-stable states, and some high-energy states after sufficiently long simulations. However, the probability of sampling high-energy states or other meta-states separated by an energy barrier is very low under finite-time simulations, leading to the occurrence of rare events.</p>
							 </aside>
						</div>
					</section>
					<section data-auto-animate>
						<h4>Enhanced sampling based on bias potential:</h4>
						<div style="overflow-y: auto; max-height: 400px;">
							<li>
								Umbrella Sampling 
								<cite>Torrie, Glenn M., and John P. Valleau. "Nonphysical sampling distributions in Monte Carlo free-energy estimation: Umbrella sampling." Journal of Computational Physics 23.2 (1977): 187-199.</cite>
							</li>
							<li>
								Histogram Reweighting
								<cite>
									Kumar, Shankar, et al. "The weighted histogram analysis method for free‐energy calculations on biomolecules. I. The method." Journal of computational chemistry 13.8 (1992): 1011-1021.
								</cite>
							</li>
							<li>
								Metadynamics 
								<cite>
									Laio, Alessandro, and Michele Parrinello. "Escaping free-energy minima." Proceedings of the national academy of sciences 99.20 (2002): 12562-12566.
								</cite>
								<cite>
									Barducci, Alessandro, Giovanni Bussi, and Michele Parrinello. "Well-tempered metadynamics: a smoothly converging and tunable free-energy method." Physical review letters 100.2 (2008): 020603.
								</cite>
							</li>
							<li>
								Variational Enhanced Sampling
								<cite>
									Valsson, Omar, and Michele Parrinello. "Variational approach to enhanced sampling and free energy calculations." Physical review letters 113.9 (2014): 090601.
								</cite>
							</li>
						</div>
						<h4>Enhanced sampling based on temperature:</h4>
						<aside class="notes">
							<p>To augment the likelihood of rare events in MD simulations, numerous methods, particularly those based on bias potential, have been developed. These methods exhibit commendable performance in exploring and constructing FES in lower dimensions. However, in higher dimensions, these methods, reliant on histogram-based probability estimation, confront the curse of dimensionality.</p>
						 </aside>
					</section>
					<section data-auto-animate>
						<h4>Enhanced sampling based on bias potential:</h4>
						<h4>Enhanced sampling based on temperature:</h4>
						<div style="overflow-y: auto; max-height: 400px;">
							<li>Temperature-accelerated Molecular Dynamics</li>
							<cite>
								Maragliano, Luca, and Eric Vanden-Eijnden. "A temperature accelerated method for sampling free energy and determining reaction pathways in rare events simulations." Chemical physics letters 426.1-3 (2006): 168-175.
							</cite>
							<li>Adiabatic Free Energy Dynamics  </li>
							<cite>
								Rosso, Lula, et al. "On the use of the adiabatic molecular dynamics technique in the calculation of free energy profiles." The Journal of chemical physics 116.11 (2002): 4389-4402.
							</cite>
							<cite>
								Abrams, Jerry B., and Mark E. Tuckerman. "Efficient and direct generation of multidimensional free energy surfaces via adiabatic dynamics without coordinate transformations." The Journal of Physical Chemistry B 112.49 (2008): 15742-15757.
							</cite>
						</div>
						<aside class="notes">
							<p>Alternative methods introduce artificial temperature to accelerate the sampling exploration task. However, the efficacy of these methods in constructing high-dimensional energy surfaces remains to be thoroughly examined.</p>
						 </aside>
					</section>
					<section data-auto-animate>
						<h4>
							DeepVes
						</h4>
						<cite>
							Bonati, Luigi, Yue-Yu Zhang, and Michele Parrinello. "Neural networks-based variationally enhanced sampling." Proceedings of the National Academy of Sciences 116.36 (2019): 17641-17647.
						</cite>
						<aside class="notes">
							<p>Recent advancements in machine learning, particularly kernel methods and deep neural networks (DNNs), have shown promising results in representing multi-dimensional FES. However, optimizing the training set remains a fundamental challenge, especially as the number of Collective Variables (CVs) increases. DeepVes, for instance, enables efficient sampling of the CV space by jointly constructing the bias potential and the target distribution, but accurately reconstructing explicit FES still requires the estimation of high-dimensional PDFs from the samples.</p>
						 </aside>
					</section>
					<section data-auto-animate>
						<h4>
							DeepVes
						</h4>
						<h4>
							Generative Method
						</h4>
						<cite>
							Noé, F., et al. "Boltzmann generators: Sampling equilibrium states of many-body systems with deep learning. Science 365, eaaw1147." (2019).
						</cite>
						<cite>
							Gabrié, Marylou, Grant M. Rotskoff, and Eric Vanden-Eijnden. "Adaptive Monte Carlo augmented with normalizing flows." Proceedings of the National Academy of Sciences 119.10 (2022): e2109420119.
						</cite>
						<aside class="notes">
							<p>Recent advancements have focused on the direct approximation of the transition operator using generative models, which is particularly beneficial when representative configurations are known a priori.</p>
						 </aside>
					</section>
					<section data-auto-animate>
						<h4>
							DeepVes
						</h4>
						<h4>
							Generative Method
						</h4>
						<h4>
							Reinforce Dynamics
						</h4>
						<cite>
							Zhang, Linfeng, and Han Wang. "Reinforced dynamics for enhanced sampling in large atomic and molecular systems." The Journal of chemical physics 148.12 (2018).
						</cite>
						<cite>
							Wang, Dongdong, et al. "Efficient sampling of high-dimensional free energy landscapes using adaptive reinforced dynamics." Nature Computational Science 2.1 (2022): 20-29.
						</cite>
						<aside class="notes">
							<p>Reinforced dynamics proposes an efficient approach to impose adaptivity by using an uncertainty indicator to bias MD simulations. This approach relies on calculating the standard deviation of the predictions from multiple DNNs trained on the same dataset.</p>
						 </aside>
					</section>
					<section data-auto-animate>
						<h4>
							Min-Max formulation
						</h4>
						<div data-id="loss">
							\[
							\MLMN(\bz) = \|\nabla_\bz A_{\mathcal N}(\bz) + \bF(\bz))\|
							\]
						</div>
						<aside class="notes">
							<p>In this study, we introduce a Consensus-Based Enhanced Sampling (CES) method, designed to efficiently construct high-dimensional Free Energy Surfaces (FES). The core concept is to formulate the construction as a min-max problem, where the min-problem is focused on optimizing the Deep Neural Network (DNN) parameters for the FES representation. In this context, \( A \) represents the FES constructed by the neural network \( N \), \( F \) denotes the sampled force in \( z \), and \( L \) is the L2 vector norm at points \( z \).</p>
						</aside>
					</section>
					<section data-auto-animate>
						<h4>
							Min-Max formulation
						</h4>
						<div data-id="loss">
							\[
							\MLMN(\bz) = \|\nabla_\bz A_{\mathcal N}(\bz) + \bF(\bz))\|
							\]
						</div>
						<div data-id="interproduce">
							\[
							(\MLMN,q) = \int_\Gamma \MLMN(\bz) q(\bz) \intd\bz
							\]
						</div>
						<aside class="notes">
							<p>Rather than solely optimizing the network, we introduce a probability density function, \( q \). In the instance of uniform sampling, \( q \) is unity.</p>
						 </aside>
					</section>
					<section data-auto-animate>
						<h4>
							Min-Max formulation
						</h4>
						<div data-id="loss">
							\[
							\MLMN(\bz) = \|\nabla_\bz A_{\mathcal N}(\bz) + \bF(\bz))\|
							\]
						</div>
						<div data-id="interproduce">
							\[
							(\MLMN,q) = \int_\Gamma \MLMN(\bz) q(\bz) \intd\bz
							\]
						</div>
						<div>
							\[
							\min_{A_\mathcal{N}}\max_q (\MLMN,q)
							\]
						</div>
						<aside class="notes">
							<p>The objective is to maximize the error with respect to \( q \), providing a nuanced approach to addressing the challenges associated with constructing high-dimensional Free Energy Surfaces (FES).</p>
						 </aside>
					</section>
					<section data-auto-animate>
						<h4>
							Min-Max formulation
						</h4>
						<div>
							\[
							\max_q (\MLMN,q)
							\]
						</div>
						\(\delta(\bz-\bz^*)\), where \(\bz^{\ast} = \arg\max \MLMN(\bz)\)
						<aside class="notes">
							<p>Given a fixed network \( N \), the solution to the maximum problem can be analytically determined, resulting in a delta distribution at the point of maximum error.</p>
						 </aside>
					</section>

					<section data-auto-animate>
						<h4>
							Min-Max formulation
						</h4>
						<div data-id="entropy">
							\[
							\min_{q} \int (-\MLMN(\bz) + \kappa_h \ln q(\bz)) q(\bz) \intd \bz 
							\]
						</div>
						<aside class="notes">
							<p>However, in optimizing the distribution, it is also essential to explore the region near the point of maximum error. Consequently, we introduce entropy regularization, signified by the addition of a negative sign and an entropy term in the equation.</p>
						 </aside>
					</section>

					<section data-auto-animate>
						<h4>
							Min-Max formulation
						</h4>
						<div data-id="entropy">
							\[
							\min_{q} \int (-\MLMN(\bz) + \kappa_h \ln q(\bz)) q(\bz) \intd \bz 
							\]
						</div>
						<div>
							\[
							q^*(\bz)=\exp(-\kappa_h \MLMN^-(\bz))/Z^*
							\]
						</div>
						<aside class="notes">
							<p>The problem is convex for a Probability Density Function (PDF) \( q \), with a unique global minimum. The parameter \( \kappa_h \) serves as a Lagrangian multiplier, balancing the focus between peak concentration and the scope of exploration. It bears resemblance to the inverse temperature in statistical mechanics. A higher value of \( 1/\kappa_h \) results in a distribution closer to uniform, while a lower value leads to a distribution concentrated near the point of maximum residue.</p>
						 </aside>
					</section>
					<section data-auto-animate>
						<h4>
							Consensus based Sampling
						</h4>
						<cite>
							Carrillo, J. A., Hoffmann, F., Stuart, A. M., & Vaes, U. (2022). Consensus‐based sampling. Studies in Applied Mathematics, 148(3), 1069-1140.
						</cite>
						<cite>
							Pinnau, R., Totzeck, C., Tse, O., & Martin, S. (2017). A consensus-based model for global optimization and its mean-field limit. Mathematical Models and Methods in Applied Sciences, 27(01), 183-204.
						</cite>
						<cite>
							Carrillo, J. A., Choi, Y. P., Totzeck, C., & Tse, O. (2018). An analytical framework for consensus-based global optimization method. Mathematical Models and Methods in Applied Sciences, 28(06), 1037-1066.
						</cite>
						<cite>
							Carrillo, J. A., Jin, S., Li, L., & Zhu, Y. (2021). A consensus-based global optimization method for high dimensional machine learning problems. ESAIM: Control, Optimisation and Calculus of Variations, 27, S5.
						</cite>
						<cite>
							Chen, J., Jin, S., & Lyu, L. (2020). A Consensus-Based Global Optimization Method with Adaptive Momentum Estimation. Communications in Computational Physics.
						</cite>
						<aside class="notes">
							Directly applying existing adversarial generative models isn’t feasible due to the a priori unknown global residual error. Creating a network to represent the target distribution q or error function 
							L isn’t any simpler than reconstructing FES. We utilize consensus-based sampling through a stochastic interacting particle system, governed by over-damped Langevin dynamics. An adaptive quadratic potential helps probe the local maximum error regime, leveraging the Laplace approximation in a low-temperature limit.
							</aside>
					</section>
					<section data-auto-animate>
						<h4>
							Exploitation and exploration in the max-problem
						</h4>
						<div data-id="LDT">
							\[
							\lim_{\kappa\to\infty}\left(-\frac{1}{\kappa}\log\left(\int \exp{(-\kappa f(\bz))}\intd\rho^*(\bz)\right)\right) = f(\bz^*)
							\]
						</div>
						<aside class="notes">
   							To approximate the target distribution, particularly near the max-residual point, we draw upon Laplace's principle from large deviations theory, expressed as: [Equation]. This holds for any compactly supported probability measure \(\rho^{\ast}\), with the max-residual point \(\bz^{\ast} \in \supp(\rho^*)\) being the unique minimizer of function \(f\).
						</aside>
					</section>
					<section data-auto-animate>
						<h4>
							Exploitation and exploration in the max-problem
						</h4>
						<div data-id="LDT">
							\[
							\lim_{\kappa\to\infty}\left(-\frac{1}{\kappa}\log\left(\int \exp{(-\kappa f(\bz))}\intd\rho^*(\bz)\right)\right) = f(\bz^*)
							\]
						</div>
						<div>
							\[
							\begin{split}
							\mbm = \int \bz p(\bz)\intd \bz  \approx 
							\sum_{i=1}^{N_w} \mb z^i \hat{p}(\mb z^i) \\
							 \hat{p} (\mb z) =  \frac{\exp {(-\kappa_l \MLMN^-(\bz^i))}}{\sum_{i=1}^{N_w}\exp {(-\kappa_l \MLMN^-(\bz^i)})}
							\end{split}
							\]
						</div>

						<aside class="notes">
   							This approach allows us to pinpoint the max-residual point from a sample collection using the first-order momentum $\bm$, under the weighted density function $p(\bz)$, with $\kappa_l^{-1}$ representing a low-temperature limit. Nonetheless, the integration faces the challenge of the curse of dimensionality as the number of CVs escalates.
						</aside>
					</section>
					<section data-auto-animate>
						<h4>
							Exploitation and exploration in the max-problem
						</h4>
						<div>
							\[
							\dot{\bz}^i_t = - \frac{1}{\gamma}\nabla_\bz G(\bz^i_t;\mb m_t ,V_t) + \sqrt{\frac{2}{\kappa_h\gamma}} \mathbf\xi_i(t)
							\]
						</div>
						<div>
							\[
							G(\bz_t;\mb m_t ,V_t)=\frac{1}{2} (\bz_t-\mbm_t)^T V_t^{-1}(\bz_t-\mbm_t)
							\]
						</div>
						<aside class="notes">
   							We view the sampler \( \bz^i \) as a random walker \( \bz^i_t \), governed by the McKean stochastic differential equation, allowing adaptability and reactivity to the system's current state, steering the random walkers towards the region of large residual error represented by \( \bm_t \). The adaptively constructed conservative potential function \( G(\bz_t) \) guides individual particles towards \( \bm_t \), indicative of the region of large residual error. It’s vital to highlight that \( \bm_t \) is influenced by prior sampling, making \( \mathcal{A}(\bz_t) \) adaptable and reactive to the system's current state. The equation's stochastic term denotes the standard Gaussian white noise, characterized by zero mean and covariance, with \( \gamma \) as the friction coefficient. The equilibrium between exploitation and exploration is managed through two temperatures $\kappa_l^{-1}$ and $\kappa_h^{-1}$. A decrease in $\kappa_l^{-1}$ concentrates the random walker distribution near the current model's max-residual points, signifying exploitation, while an increase in $\kappa_h^{-1}$ progressively smoothens the distribution, fostering exploration of unknown regions.
						</aside>
					</section>
					<section data-auto-animate>
						<h4>
							Exploitation and exploration in the max-problem
						</h4>
						<div>
							\[
							\dot{\bz}^i_t = - \frac{1}{\gamma}\nabla_\bz G(\bz^i_t;\mb m_t ,V_t) + \sqrt{\frac{2}{\kappa_h\gamma}} \mathbf\xi_i(t)
							\]
						</div>
						<div>
							\[
							\begin{split}
							\mbm_{t} &= \sum_{i=1}^{N_{w}}\bz^i_t \hat{p}(\bz^i_t),
							V_{t} &= \kappa_t\sum_{i=1}^{N_{w}} (\bz^i_t-\mbm_t)(\bz^i_t-\mbm_t)^T \hat{p}(\bz^i_t),
							\end{split}
							\]
							where \(\kappa_t = \kappa_l + \kappa_h\) and \(\quad \hat{p} (\mb z) =  \frac{\exp {(-\kappa_l \MLMN^-(\bz))}}{\sum_{i=1}^{N_w}\exp {(-\kappa_l \MLMN^-(\bz^i)})}\)
						</div>
						<aside class="notes">
							we want show that the sampling distribution governed by converges to a steady state as an quaditical approximation of $q^{\ast}$ given the proper choices of $\bm_t$ and $V_t$ 
						 </aside>
						 
					</section>
					<section data-auto-animate>
						<div class="proposition" data-id="proposition1">
							<ul>
								<div>Proposition 1:</div>
								<div class="content">
									Suppose \( \mathcal{L}^- (\mathbf{z}) \) takes a local quadratic approximation in the form of \( \frac{1}{2} (\mathbf{z} - \boldsymbol{\mu})^T \Sigma^{-1} (\mathbf{z} - \boldsymbol{\mu}) \), \( q_t \to \frac{\exp{(-\kappa_h \mathcal{L}^- (\mathbf{z}))}}{\int \exp {(-\kappa_h \mathcal{L}^- (\mathbf{z}))} \, d\mathbf{z}} \) as \( t \to \infty \), given \( \kappa_t = \kappa_l + \kappa_h \).
								</div>
							</ul>
						</div>
						<aside class="notes">
							However, a good quadratic approximation isn’t explicitly defined. What we can assert is that if the error space assumes a quadratic form, we can rigorously demonstrate convergence to the desired \( q \).
						</aside>
					</section>
					<section data-auto-animate>
						<div class="proposition" data-id="proposition1">
							<ul>
								<div>Proposition 1:</div>
								<div class="content">
									Suppose \( \mathcal{L}^- (\mathbf{z}) \) takes a local quadratic approximation in the form of \( \frac{1}{2} (\mathbf{z} - \boldsymbol{\mu})^T \Sigma^{-1} (\mathbf{z} - \boldsymbol{\mu}) \), \( q_t \to \frac{\exp{(-\kappa_h \mathcal{L}^- (\mathbf{z}))}}{\int \exp {(-\kappa_h \mathcal{L}^- (\mathbf{z}))} \, d\mathbf{z}} \) as \( t \to \infty \), given \( \kappa_t = \kappa_l + \kappa_h \).
								</div>
							</ul>
						</div>
							<div class="proposition">
								<ul>
								<h4>Remark 1 </h4>
								<cite>
									(Theorem 3.9) Carrillo, José A., et al. "Consensus‐based sampling." Studies in Applied Mathematics 148.3 (2022): 1069-1140.
								</cite>
								<div class="content">
									<p>If \( \mathcal{L}^{-}(\mathbf{z}) \in C^2 \) and its Hessian matrix is positive defined with bounds from below and above, i.e. \( u \mathbf{I} \succeq U \succeq D^2 \mathcal{L}^{-1}(\mathbf{z}) \succeq L \succeq l\mathbf{I} \) for some positive numbers \( u \) and \( l \), then there exists a \( \hat{\beta} \) such that, for all \( 0 < \beta_l^{-1} \leq \hat{\beta}^{-1} \), the dynamics admit a Gaussian steady state \( \frac{\exp{(-\kappa_h\mathcal{A}(\mathbf{z}))}}{\int \exp{(-\kappa_h\mathcal{A}(\mathbf{z}))} \, d\mathbf{z}} \), where \( \mathcal{A}(\mathbf{z}) = \frac{1}{2} (\mathbf{z} - \boldsymbol{m})^T V^{-1}(\mathbf{z} - \boldsymbol{m}) \) and satisfying \( U^{-1} \preceq V^{-1} \preceq L^{-1} \) and \( \|\boldsymbol{m} - \mathbf{z}^*\| = O(\beta_l^{-1}) \).</p>
								</div>
							</ul>
						</div>
						<aside class="notes">
						The initial remark is that even if the error isn’t quadratic, but the Hessian matrix is positively defined with upper and lower bounds, the algorithm’s correction can be justified, as the distribution function is also constrained by related bounds.
						</aside>
					</section>
					<section data-auto-animate>
						<div class="proposition" data-id="proposition1">
							<ul>
								<div>Proposition 1:</div>
								<div class="content">
									Suppose \( \mathcal{L}^- (\mathbf{z}) \) takes a local quadratic approximation in the form of \( \frac{1}{2} (\mathbf{z} - \boldsymbol{\mu})^T \Sigma^{-1} (\mathbf{z} - \boldsymbol{\mu}) \), \( q_t \to \frac{\exp{(-\kappa_h \mathcal{L}^- (\mathbf{z}))}}{\int \exp {(-\kappa_h \mathcal{L}^- (\mathbf{z}))} \, d\mathbf{z}} \) as \( t \to \infty \), given \( \kappa_t = \kappa_l + \kappa_h \).
								</div>
							</ul>
						</div>
							<div class="proposition">
								<ul>
								<h4>Remark 2 </h4>
								<cite>
									(Theorem 3.1) Carrillo, José A., et al. "A consensus-based global optimization method for high dimensional machine learning problems." ESAIM: Control, Optimisation and Calculus of Variations 27 (2021): S5.
								</cite>
								<div class="content">
									
									<p>The convergence of the method, which is exponential in time, is guaranteed with parameter constraints independent of the dimensionality.</p>
								</div>
							</ul>
							<aside class="notes">
								Although all proofs are within the realm of Mean Field Theory, where the number of particles must approach infinity, convergence is assured with parameter constraints that are independent of dimensionality, thereby overcoming the curse of dimensionality.
							</aside>
						</div>
					</section>
					<section data-auto-animate>
						<div class="proposition" data-id="proposition1">
							<ul>
								<div>Proposition 1:</div>
								<div class="content">
									Suppose \( \mathcal{L}^- (\mathbf{z}) \) takes a local quadratic approximation in the form of \( \frac{1}{2} (\mathbf{z} - \boldsymbol{\mu})^T \Sigma^{-1} (\mathbf{z} - \boldsymbol{\mu}) \), \( q_t \to \frac{\exp{(-\kappa_h \mathcal{L}^- (\mathbf{z}))}}{\int \exp {(-\kappa_h \mathcal{L}^- (\mathbf{z}))} \, d\mathbf{z}} \) as \( t \to \infty \), given \( \kappa_t = \kappa_l + \kappa_h \).
								</div>
							</ul>
						</div>
							<div class="proposition">
								<ul>
								<h4>Remark 3 </h4>
								<div class="content">
									<p>We note that the kinetic processes of a molecular system are generally characterized by the local minima and saddles points on the FES. On the other hand, the regimes of high free energy are less relevant. To accurately construct these thermodynamically accessible regimes, we modify the loss function \( \mathcal{L} \) as</p>
									<div>
										\[ \mathcal{L}(\mathbf{z}) = \frac{ \|\nabla_\mathbf{z} A_{\mathcal N}(\mathbf{z}) + \mathbf{F}(\mathbf{z})\|}{\|\mathbf{F}(\mathbf{z})\|+e} \]
									</div>
								</div>
							</ul>
						</div>
					</section>
					<section data-auto-animate>
						<h4>
						Numerical Result	
						</h4>
							<div style="display: flex; justify-content: center; align-items: center;">
								<div>
									<small>
									<table>
										<thead>
											<tr>
												<th rowspan="2">Method</th>
												<th colspan="2">Accuracy</th>
												<th colspan="3">Time</th>
											</tr>
											<tr>
												<th>\(l_2\) error</th>
												<th>\(l_\infty\) error</th>
												<th>Simulation</th>
												<th>Train</th>
												<th>Total</th>
											</tr>
										</thead>
										<tbody>
											<tr>
												<td rowspan="2">VES</td>
												<td>5.39</td>
												<td>21.03</td>
												<td colspan="3">47.5</td>
											</tr>
											<tr></tr>
											<tr>
												<td rowspan="2">RiD</td>
												<td>1.52</td>
												<td>9.46</td>
												<td>6.25</td>
												<td>3.79(GPU)</td>
												<td>10.04</td>
											</tr>
											<tr></tr>
											<tr>
												<td rowspan="2">CES</td>
												<td rowspan="2">1.45</td>
												<td rowspan="2">6.74</td>
												<td rowspan="2">0.88 × 10</td>
												<td>0.18(CPU)</td>
												<td>8.98</td>
											</tr>
											<tr>
												<td>0.13(GPU)</td>
												<td>8.93</td>
											</tr>
											<tr></tr>
										</tbody>
									</table>
								</small>
								</div>
							<div
								id=ala2
								class="plotly-graph-div"
								style="height:400; width:400;">
							</div>
							<script type="text/javascript" src="./text/ala2.js">
							</script>
						</div>
					</section>
					<section data-auto-animate>
						<h4>Numerical Result</h4>
						<div style="display: flex; flex-direction: center; align-items: center;">
							<div>
								<small>
									<table border="1" cellspacing="0" cellpadding="8">
										<thead>
											<tr>
												<th rowspan="2">Method</th>
												<th colspan="3">Time</th>
											</tr>
											<tr>
												<th>Simulation</th>
												<th>Train</th>
												<th>Total</th>
											</tr>
										</thead>
										<tbody>
											<tr>
												<td>RiD</td>
												<td>117</td>
												<td>79 (GPU)</td>
												<td>196</td>
											</tr>
											<tr>
												<td>CES</td>
												<td>4.81×20</td>
												<td>0.66 (GPU)</td>
												<td>97</td>
											</tr>
										</tbody>
									</table>
								</small>
							</div>
							<div style="overflow-y: auto; max-height: 400px;">
								<div id="chi1_psi_15" class="plotly-graph-div" style="height:500px; width:600px;">
									<small>\(\psi=1.5\)</small>
								</div>
								<div id="chi1_phi_10" class="plotly-graph-div" style="height:500px; width:600px;">
									<small>\(\phi=1.0\)</small>
								</div>
								<div id="chi1_ome_15" class="plotly-graph-div" style="height:500px; width:600px;">
									<small>\(\omega=1.5\)</small>
								</div>
								<script type="text/javascript" src="./text/chi1.js"></script>
							</div>
						</div>
					</section>
					<section data-auto-animate>
						<h4>Numerical Result</h4>
						<div>
							<div style="overflow-y: auto; max-height: 400px;">
								<div id="phi1_psi1" class="plotly-graph-div" style="height:400px; width:600px; margin: auto;">
									<small>\(\phi_1,\psi_1\)</small>
								</div>
								<div id="phi2_phi3" class="plotly-graph-div" style="height:400px; width:600px; margin: auto;">
									<small>\(\phi_2,\phi_3\)</small>
								</div>
								<div id="psi2_psi3" class="plotly-graph-div" style="height:400px; width:600px; margin: auto;">
									<small>\(\psi_2,\psi_3\)</small>
								</div>
							</div>
							<script type="text/javascript" src="./text/ala16.js"></script>
						</div>
					</section>
					<section>
						<h4>
							Future Work
						</h4>
					</section>
					<section>
						<h4>
							Future Work: data-driven equation modeling 
						</h4>
						<h5>
							Extend the CGMD to more realistic situations
						</h5>
						<h5>
							Control Problems with Surrogated Model
						</h5>
						<h5>
							Extend these methods to other background
						</h5>
						<div style="display: flex; flex-direction: column; align-items: center;">
							<div
							id=vpb
							class="plotly-graph-div"
							style="height:300; width:300;">
						</div>
						<script type="text/javascript" src="./text/vp.js">
						</script>
						</div>
					</section>
					<section>
						<h4>
							Future Work: data-driven dynamics  variable selection
						</h4>
						<h5>
							Other methods to determine CG map, such as fisher information matrix
						</h5>
						<h5>
							Using the CG map optimzation in continuous level reheolgy modelings
						</h5>
						<h5>
						 Extend optimzation method for state-dependent friction tensor bias determination. 
						</h5>
					</section>
					<section>
						<h4>
							Future Work: consensus based enhance sampling 
						</h4>
						<h5>
							sampling high dimensional friction tensor for potein.
						</h5>
					</section>
				</div>
		</div>
		
		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
		<!-- <script src="https://cdn.example.com/reveal.js-menu/menu.js"></script>
		<script>
			Reveal.initialize({
			slideNumber: 'c/t',
			plugins: [ RevealMenu ],
			titleSelector: '',
			menu: {
				titleSelector: 'h1, h2', 
				hideMissingTitles: true
			}
		});
		</script> -->
	</body>
</html>
